{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4f507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_2_scoring(data):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import category_encoders as ce\n",
    "    import h2o\n",
    "    from h2o.estimators import H2OGradientBoostingEstimator\n",
    "    import os\n",
    "    from h2o.grid.grid_search import H2OGridSearch\n",
    "    import pickle\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    print(\"In scoring function\")\n",
    "    '''Load Artifacts'''\n",
    "    artifacts_dict_file = open(\"artifacts/artifacts_dict_file.pkl\", \"rb\")\n",
    "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
    "    artifacts_dict_file.close()\n",
    "\n",
    "    #LOad encoders\n",
    "    target_encoder = artifacts_dict[\"target_encoder\"]\n",
    "    #Load h2o model\n",
    "    #Start H2O\n",
    "    h2o.init(max_mem_size = \"4G\")             #specify max number of bytes. uses all cores by default.\n",
    "    h2o.remove_all()                          #clean slate, in case cluster was already running\n",
    "    model = h2o.load_model(path='artifacts/best_model')\n",
    "    \n",
    "    '''Transform dataset'''\n",
    "    #Clean dataset\n",
    "    \n",
    "    #Convert the strings styled as '$XXXX.XX' to float values. Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv'] #This helps us to convert them into float values as they are numerical values\n",
    "    Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
    "    for col in Columns:\n",
    "        data[col] = data[col].apply(lambda x: x.replace(',', '').replace('$',''))\n",
    "        data[col] = data[col].astype(float)\n",
    "    #Convert columns to categorical\n",
    "    cat_columns = [\"City\",\"State\",\"Bank\",\"BankState\", \"NewExist\", \"RevLineCr\",\"LowDoc\",\"Zip\"]\n",
    "    #Ensure the above columns are categorical in the data\n",
    "    data[cat_columns] = data[cat_columns].astype(object)\n",
    "    \n",
    "    #Fill missing values\n",
    "    for col in data.columns:\n",
    "        if data[col].isna().any() == True:\n",
    "            if data[col].dtype == 'object':\n",
    "                data[col].fillna(data[col].mode()[0],inplace=True)\n",
    "            elif data[col].dtype == 'float64' or data[col].dtype == 'int64':\n",
    "                data[col].fillna(data[col].mean(),inplace=True)  \n",
    "    \n",
    "    #Drop index column\n",
    "    data.drop(\"index\",axis=1,inplace=True)\n",
    "    \n",
    "    #Feature Engineering\n",
    "    #NAICS Code - This helps us to extract the first 2 digits from the NAICS code. The first two digits of the NAICS code specify the industry. Hence it makes sense to have the NAICS code as an emgineered feature\n",
    "    data['NAICS_Code'] = data['NAICS'].apply(lambda x : str(x)[0:2])\n",
    "    data['NAICS_Code'] = data['NAICS_Code'].astype('object')\n",
    "    data.drop(\"NAICS\", axis = 1,inplace=True)\n",
    "    \n",
    "    #Similarly apply binning on NoEmp column\n",
    "    groups = ['Low', 'Med', 'High', 'Very High']\n",
    "    bins = [-1, 1000, 5000, 7500,9999]\n",
    "    data['NoEmp_cut'] = pd.cut(data['NoEmp'], labels=groups,bins=bins)\n",
    "    data.drop(\"NoEmp\", axis = 1,inplace=True)\n",
    "    \n",
    "    #Similarly apply binning on CreateJob column\n",
    "    groups = ['Low', 'Med', 'High', 'Very High']\n",
    "    bins = [-1, 100, 5000, 7500,9999]\n",
    "    data['CreateJob_cut'] = pd.cut(data['CreateJob'], labels=groups,bins=bins)\n",
    "    data.drop(\"CreateJob\", axis = 1,inplace=True)\n",
    "    \n",
    "    #Similarly apply binning on RetainedJob column\n",
    "    groups = ['Low', 'Med', 'High', 'Very High']\n",
    "    bins = [-1, 100, 5000, 7500,9999]\n",
    "    data['RetainedJob_cut'] = pd.cut(data['RetainedJob'], labels=groups,bins=bins)\n",
    "    data.drop(\"RetainedJob\", axis = 1,inplace=True)\n",
    "    \n",
    "    #DisbursementGross column\n",
    "    data['log_DisbursementGross'] = np.log2(data['DisbursementGross']+1)\n",
    "    data.drop(\"DisbursementGross\", axis = 1,inplace=True)\n",
    "    \n",
    "    #GrAppv column\n",
    "    data['log_GrAppv'] = np.log2(data['GrAppv'])\n",
    "    data.drop(\"GrAppv\", axis = 1,inplace=True)\n",
    "    \n",
    "    #SBA_Appv column\n",
    "    data['log_SBA_Appv'] = np.log2(data['SBA_Appv'])\n",
    "    data.drop(\"SBA_Appv\", axis = 1,inplace=True)\n",
    "    \n",
    "    #BalanceGross column\n",
    "    data['log_BalanceGross'] = np.log2(data['BalanceGross']+1)\n",
    "    data.drop(\"BalanceGross\", axis = 1,inplace=True)\n",
    "    \n",
    "    #Gross of DisbursementGross per franchise\n",
    "    data['Franchise_DisbursementGross_Mean'] = data.groupby(['FranchiseCode'])['log_DisbursementGross']\\\n",
    "                                     .transform(lambda x: x.mean())\n",
    "    \n",
    "    #Convert New EXist column to categorical\n",
    "    data[\"NewExist\"] = data[\"NewExist\"].astype(object)\n",
    "    \n",
    "    cat_columns_new = cat_columns + [\"NoEmp_cut\",\"CreateJob_cut\",\"RetainedJob_cut\"]\n",
    "    \n",
    "    ##Encoding categorical variables\n",
    "    #Columns to drop from ML models\n",
    "    cols_to_drop = []\n",
    "    #Categorical encoders disctionary\n",
    "    cat_encoders = {}\n",
    "    #New categorical (encoded) columns\n",
    "    cat_enc_columns = []\n",
    "    \n",
    "    for col in cat_columns_new:\n",
    "        if data[col].dtype == 'object' or data[col].dtype == 'category':\n",
    "            if data[col].nunique() < 10:\n",
    "                print(\"encoded \", col)\n",
    "                '''Encode Testing'''\n",
    "                cat_enc_columns = cat_enc_columns + ohe_columns\n",
    "                result_test = pd.DataFrame(result, columns=ohe_columns)\n",
    "                result_test.index = data.index\n",
    "                data = pd.concat([data, result_test], axis=1)\n",
    "                cat_encoders[col] = [deepcopy(enc),\"ohe\"]\n",
    "                data[col+\"_Unknown\"]=0\n",
    "        cols_to_drop.append(col)\n",
    "    \n",
    "    #Adding columns for target encoding, remove the original columns\n",
    "    trg_columns = [\"City\",\"State\",\"Bank\",\"BankState\", \"RevLineCr\",\"Zip\"]\n",
    "    \n",
    "    for col in trg_columns:\n",
    "        data[col+\"_trg\"] = data[col]\n",
    "    \n",
    "    #print(data.columns)\n",
    "    \n",
    "    tar_enc_cols = encoder.get_feature_names()\n",
    "        \n",
    "    #Handle categories in test dataset that are not there in train dataset\n",
    "    for col in data.columns:\n",
    "        if(col not in tar_enc_cols):\n",
    "            print(\"Removing column: \",col)\n",
    "            data[(\"_\".join((col).split(\"_\")[:-1]))+\"_Unknown\"]= data[col]\n",
    "            data.drop(col,axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    data = target_encoder.transform(data)\n",
    "    \n",
    "    #Drop original columns\n",
    "    data.drop(cat_columns_new,axis=1,inplace=True)\n",
    "    \n",
    "    data.to_csv(\"transformed_data.csv\")\n",
    "\n",
    "    #Convert pandas dataframe to h2o frame\n",
    "    h2o_data = h2o.H2OFrame(data)\n",
    "    h2o_data = h2o_data.asnumeric()\n",
    "    \n",
    "    print(h2o_data.head(5))\n",
    "    \n",
    "    '''Score dataset'''\n",
    "    #Score the dataset using the model\n",
    "    prediction = (model.predict(h2o_data)).as_data_frame()\n",
    "    prediction.reset_index()\n",
    "    prediction.rename(columns={'predict':'label','p0':'probability_0','p1':'probability_1'})\n",
    "    print(prediction)\n",
    "    \n",
    "    '''Return pandas DF'''\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf7ffab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.951011</td>\n",
       "      <td>0.048989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.936405</td>\n",
       "      <td>0.063595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.103346</td>\n",
       "      <td>0.896654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.757923</td>\n",
       "      <td>0.242077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.961737</td>\n",
       "      <td>0.038263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict  probability_0  probability_1\n",
       "0        0       0.951011       0.048989\n",
       "1        0       0.936405       0.063595\n",
       "2        1       0.103346       0.896654\n",
       "3        0       0.757923       0.242077\n",
       "4        0       0.961737       0.038263"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load new data and remove the target column (if it's present)\n",
    "import pandas as pd\n",
    "import pickle\n",
    "new_data = pd.read_csv('C:\\Shiva Files\\Shiva SSD\\Shiva\\MSBA Cohort\\Semester 2\\Applied Machine Learning\\Project 1\\SBA_loans_project_2_holdout_students_valid.csv')\n",
    "\n",
    "# Get predictions using the scoring function\n",
    "results_df = project_2_scoring(new_data)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977d11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
