{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4f507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import category_encoders as ce\n",
    "\n",
    "def project_1_scoring(input_df: pd.DataFrame):\n",
    "    # Load the saved model and encoders\n",
    "    logReg = pickle.load(open('./artifacts3/LogisticRegressionModel.pkl', 'rb'))\n",
    "    one_hot_encoder = pickle.load(open('./artifacts3/one_hot_encoder.pkl', 'rb'))  \n",
    "    woe_encoder =  pickle.load(open('./artifacts3/woe_encoder.pkl', 'rb'))\n",
    "    glm_model = pickle.load(open('./artifacts3/glm.pkl', 'rb'))\n",
    "    \n",
    "    # Consider rows without missing values in target column mis_status\n",
    "    input_df= input_df.query('MIS_Status != \"Missing\"')\n",
    "\n",
    "    # Remove index column\n",
    "    input_df.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    # Replace encode Na/Null values\n",
    "    input_df.fillna(0, inplace=True)\n",
    "    input_df.isnull().values.any()\n",
    "        # Replace null values for string data type columns\n",
    "    string_cols_names = input_df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    for col in string_cols_names:\n",
    "        input_df[col].fillna('Missing',inplace= True)\n",
    "\n",
    "    # Replace null values for float data type columns\n",
    "    float_cols_names= input_df.select_dtypes(include='float').columns.tolist()\n",
    "\n",
    "    for col in float_cols_names:\n",
    "        input_df[col]=input_df[col].fillna(input_df[col].mode()[0])\n",
    "\n",
    "    input_df.isnull().values.any()\n",
    " \n",
    "    \n",
    "    # One-hot encoding\n",
    "    input_df = one_hot_encoder.transform(input_df)\n",
    "    \n",
    "    # WOE encoding\n",
    "    input_df = woe_encoder.transform(input_df)\n",
    "    \n",
    "    # Rename columns\n",
    "    # Define a dictionary to map old column names to new ones\n",
    "    column_names = {\n",
    "    'City': 'City_woe',\n",
    "    'State': 'State_woe',\n",
    "    'Bank': 'Bank_woe',\n",
    "    'BankState': 'Bankstate_woe',\n",
    "    'RevLineCr': 'RevLinecr_woe',\n",
    "    'Zip':'Zip_woe',\n",
    "    'NAICS':'NAICS_woe',\n",
    "    'NoEmp':'NoEmp_woe',\n",
    "    'NewExist':'NewExist_woe',\n",
    "    'CreateJob':'CreateJob_woe',\n",
    "    'RetainedJob':'RetainedJob_woe',\n",
    "    'FranchiseCode':'FranchiseCode_woe',\n",
    "    'UrbanRural':'UrbanRural_woe',\n",
    "    'DisbursementGross':'DisbursementGross_woe',\n",
    "    'BalanceGross':'BalanceGross_woe',\n",
    "    'GrAppv':'GrAppv_woe',\n",
    "    'SBA_Appv':'SBA_Appv_woe'}\n",
    "    input_df.rename(columns=column_names, inplace=True)\n",
    "    \n",
    "    # GLM transformation\n",
    "    input_df_glm = glm_model.predict(input_df[['SBA_Appv_woe', 'UrbanRural_woe', 'NoEmp_woe', 'GrAppv_woe']])\n",
    "    \n",
    "\n",
    "    # Add GLM columns\n",
    "    def add_glm_columns(input_df, glm_data):\n",
    "        input_df[\"GLM1\"] = glm_data\n",
    "        features = ['SBA_Appv_woe', 'UrbanRural_woe', 'NoEmp_woe', 'GrAppv_woe']\n",
    "        for i, feature in enumerate(features):\n",
    "            input_df[f\"GLM{i+2}\"] = glm_data * input_df[feature]\n",
    "    add_glm_columns(input_df, input_df_glm)\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    y_pred_prob = logReg.predict_proba(input_df.drop('MIS_Status',axis=1))[:, 1]\n",
    "    y_pred_class = (y_pred_prob >= 0.4).astype(int)\n",
    "\n",
    "    # Create the output DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        \"record_index\": input_df.index,\n",
    "        \"predicted_class\": y_pred_class,\n",
    "        \"probability_0\": 1 - y_pred_prob,\n",
    "        \"probability_1\": y_pred_prob\n",
    "    })\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf7ffab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   record_index  predicted_class  probability_0  probability_1\n",
      "0             0                0       0.951011       0.048989\n",
      "1             1                0       0.936405       0.063595\n",
      "2             2                1       0.103346       0.896654\n",
      "3             3                0       0.757923       0.242077\n",
      "4             4                0       0.961737       0.038263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load new data and remove the target column (if it's present)\n",
    "import pandas as pd\n",
    "import pickle\n",
    "new_data = pd.read_csv('C:/Users/koppu/Downloads/Project 1/SBA_loans_project_1.csv')\n",
    "\n",
    "# Get predictions using the scoring function\n",
    "results_df = project_1_scoring(new_data)\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977d11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
