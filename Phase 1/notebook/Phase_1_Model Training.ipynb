{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad39a5f",
   "metadata": {},
   "source": [
    "# Applied Machine Learning : Phase 1\n",
    "**BUAN 6341**  \n",
    "**Student Name: Shiva Kumar Reddy Koppula**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbff326",
   "metadata": {},
   "source": [
    "# Project 1 Starter\n",
    "\n",
    "**Here are some tips for submitting your project. You can use the points as partial check list before submission.**\n",
    "\n",
    "- **Give your notebook a clear and descriptive title.** \n",
    "- **Explain your work in Markdown cells.** This will make your notebook easier to read and understand. You can use different colors of font to highlight important points.\n",
    "- **Remove any unnecessary code or text.** For example, you should not include the template for training and scoring in your final submission.\n",
    "- **Package your submission in a single file.** I will deduct points for multiple files or incorrect folder structure.\n",
    "- **Name your notebooks correctly.** Include your name and Net-ID in the file name.\n",
    "- **Train your TE/WOE encoders on the training set only.** You can train them on the full dataset for your final model.\n",
    "- **Test your scoring function.** Most students scoring functions in the past din't work, so make sure to test yours before submitting your project.\n",
    "- **Avoid common mistakes in your scoring function.** For example, your scoring function should not:\n",
    "  - drop records, expect the target to be passed\n",
    "  - fit TE/WOE/Scalers\n",
    "  - return anything other than a Pandas DF.\n",
    "- **Make sure you have the required number of engineered features.** \n",
    "- **Don't create features and then not use them in the model**, if there is a reason not to use the feature in the model, explain.\n",
    "- **Don't include models in your notebook that you didn't train.** This is considered cheating and will result in a grade of zero for the project.\n",
    "- **Consistently display model performance metrics.** Use AUC or AUCPR for all models and iterations, and don't switch between metrics. For sure don't use accuracy, it is misleading metric for the imbalanced datasets. \n",
    "- **Discuss your model results in a Markdown cell.** Don't just print the results; explain what they mean.\n",
    "- **Include a conclusion section in your notebook.** This is your chance to summarize your findings and discuss the implications of your work.\n",
    "- **Treat your notebook like a project report that will be read by your manager who can't read Python code.** Make sure your notebook is clear, concise, and easy to understand.\n",
    "- **Display a preview of your dataset that you used for training.** This will help me understand what features you used in your model.\n",
    "- **Use the libraries versions specified on eLearning.** For example, you should use H2O 3.44.0.3  \n",
    "- **Use Python 3.10.11.** If you use another version and your code doesn't work on 3.10.11, it will be considered a bug in your code.\n",
    "- **When running H2O and want to suppress long prints (for example model summary), include \";\" at the end of the command.**\n",
    "- **Don't include the dataset with your deliverables.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da975e3a",
   "metadata": {},
   "source": [
    "## Project Requirements Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca96cb",
   "metadata": {},
   "source": [
    "**This is draft - version 0 - changes are possible and will be announced.**\n",
    "\n",
    "Project 1 is to allow students to practice Data Science concepts learned so far.\n",
    "\n",
    "The project will include following tasks:\n",
    "- Load dataset. Don't use \"index\" column for training.\n",
    "- Clean up the data:\n",
    "    - Encode/replace missing values\n",
    "    - Replace features values that appear incorrect\n",
    "- Encode categorical variables\n",
    "- Split dataset to Train/Validation/Test\n",
    "- Add engineered features\n",
    "- Train and tune ML model\n",
    "- Provide final metrics using Test dataset\n",
    "- Provide a scoring function that can be used to score new data. You can test your scoring function on the provided \"scoring\" dataset.\n",
    "\n",
    "**Don't use PCA or TruncatedSVD for this project.** The goal of using Linear models is to be able to interpret the results via coefficients, and PCA/TruncatedSVD will make use of coefficients unusable for interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77b95f",
   "metadata": {},
   "source": [
    "### Types of models to train\n",
    "\n",
    "Your final submission should include single model. \n",
    "The model set you should try to come up with best model per type of model:\n",
    "1. Identify best model from: Sklearn Logistic Regression - try all combinations of regularization\n",
    "2. Identify best model from: H2O-3 GLM - try different combinations of regularization\n",
    "\n",
    "**Evaluation metric: AUCPR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbf8cf",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "You should train/fit categorical features scalers and encoders on Train only. Use `transform` or equivalent function on Validation/Test datasets.\n",
    "\n",
    "It is important to understand all the steps before model training, so that you can reliably replicate and test them to produce scoring function.\n",
    "\n",
    "\n",
    "You should generate various new features. Examples of such features can be seen in the Module-3 lecture on GLMs.  \n",
    "Your final model should have at least **10** new engineered features.   \n",
    "On-hot-encoding, label encoding, and target encoding **is not included in the** **10** features to create.    \n",
    "You can attempt target encoding, however the technique is not expected to produce improvement for Linear models.\n",
    "\n",
    "Ideas for Feature engineering for various types of variables:\n",
    "1. https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/transformations.html\n",
    "2. GLM lecture and hands-on (Module-3)\n",
    "\n",
    "\n",
    "**Note**: \n",
    "- You don't have to perform feature engineering using H2O-3 even if you decided to use H2O-3 GLM for model training.\n",
    "- It is OK to perform feature engineering using any technique, as long as you can replicate it correctly in the Scoring function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19881ad6",
   "metadata": {},
   "source": [
    "### Threshold calculation\n",
    "\n",
    "You will need to calculate optimal threshold for class assignment using F1 metric:\n",
    "- If using sklearn, use F1 `macro`: `f1_score(y_true, y_pred, average='macro')` \n",
    "- If using H2O-3, use F1\n",
    "\n",
    "You will need to find optimal probability threshold for class assignment, the threshold that maximizes above F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91aca84",
   "metadata": {},
   "source": [
    "### Scoring function\n",
    "\n",
    "The Project-1 will be graded based on the completeness and performance of your final model against the hold-out dataset.\n",
    "The hold-out dataset will not be known to the students. As part of your deliverables, you will need to submit a scoring function. \n",
    "\n",
    "You need to submit a scoring function for the best model you trained, either Sklearn or H2O-3 model.  \n",
    "\n",
    "The scoring function will perform the following:\n",
    "- Accept dataset in the same format as provided with the project, minus \"MIS_Status\" column\n",
    "- Load trained model and any encoders/scalers that are needed to transform data\n",
    "- Transform dataset into format that can be scored with the trained model\n",
    "- Score the dataset and return the results, for each record\n",
    "    - Record ID\n",
    "    - Record label as determined by final model (0 or 1)\n",
    "    - If your model returns probabilities, you need to assign the label based on maximum F1 threshold\n",
    "    \n",
    "Scoring function header:\n",
    "```\n",
    "def project_1_scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return labels\n",
    "    \n",
    "    \"\"\"\n",
    "    l = data.shape[0]\n",
    "    return l*[0]\n",
    "```\n",
    "\n",
    "Look for full example of scoring function at the bottom of the notebook. **Don't copy as is - this is just an example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a4d90",
   "metadata": {},
   "source": [
    "### Deliverables in a single zip file in the following structure:\n",
    "- `notebook` (folder)\n",
    "    - Jupyter notebook with complete code to manipulate data, train and tune final model. `ipynb` format.\n",
    "    - Jupyter notebook with scoring function. `ipynb` format.\n",
    "- `artifacts` (folder)\n",
    "    - Model and any potential encoders in the \"pkl\" format or native H2O-3 format (for H2O-3 model)\n",
    "    - Scoring function that will load the final model and encoders. Separate from above notebook or `.py` file\n",
    "\n",
    "\n",
    "\n",
    "Your notebook should include explanations about your code and be designed to be easily followed and results replicated. Once you are done with the final version, you will need to test it by running all cells from top to bottom after restarting Kernel. It can be done by running `Kernel -> Restart & Run All`\n",
    "\n",
    "\n",
    "**Important**: To speed up progress, first produce working code using a small subset of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d6cf8",
   "metadata": {},
   "source": [
    "## Additional Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341cb74",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "The dataset is from the U.S. Small Business Administration (SBA) The U.S. SBA was founded in 1953 on the principle of promoting and assisting small enterprises in the U.S. credit market (SBA Overview and History, US Small Business Administration (2015)). Small businesses have been a primary source of job creation in the United States; therefore, fostering small business formation and growth has social benefits by creating job opportunities and reducing unemployment. There have been many success stories of start-ups receiving SBA loan guarantees such as FedEx and Apple Computer. However, there have also been stories of small businesses and/or start-ups that have defaulted on their SBA-guaranteed loans.    \n",
    "\n",
    "\n",
    "More info on the original dataset: https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\n",
    "\n",
    "**Don't use original dataset, use only dataset provided with project requirements in eLearning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1af41",
   "metadata": {},
   "source": [
    "### Dataset preparation and clean-up\n",
    "\n",
    "Modify and clean-up the dataset as following:\n",
    "- Replace encode Na/Null values\n",
    "- Convert the strings to floats/integers as needed\n",
    "\n",
    "Any additional clean-up as you find fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9f9eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Extend cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad7bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Mar 18 18:25:50 2019\n",
    "\n",
    "@author: Uri Smashnov\n",
    "\n",
    "Purpose: Analyze input Pandas DataFrame and return stats per column\n",
    "Details: The function calculates levels for categorical variables and allows to analyze summarized information\n",
    "\n",
    "To view wide table set following Pandas options:\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth',200)\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "def describe_more(df,normalize_ind=False, weight_column=None, skip_columns=[], dropna=True):\n",
    "    var = [] ; l = [] ; t = []; unq =[]; min_l = []; max_l = [];\n",
    "    assert isinstance(skip_columns, list), \"Argument skip_columns should be list\"\n",
    "    if weight_column is not None:\n",
    "        if weight_column not in list(df.columns):\n",
    "            raise AssertionError('weight_column is not a valid column name in the input DataFrame')\n",
    "      \n",
    "    for x in df:\n",
    "        if x in skip_columns:\n",
    "            pass\n",
    "        else:\n",
    "            var.append( x )\n",
    "            uniq_counts = len(pd.value_counts(df[x],dropna=dropna))\n",
    "            uniq_counts = len(pd.value_counts(df[x], dropna=dropna)[pd.value_counts(df[x],dropna=dropna)>0])\n",
    "            l.append(uniq_counts)\n",
    "            t.append( df[ x ].dtypes )\n",
    "            min_l.append(df[x].apply(str).str.len().min())\n",
    "            max_l.append(df[x].apply(str).str.len().max())\n",
    "            if weight_column is not None and x not in skip_columns:\n",
    "                df2 = df.groupby(x).agg({weight_column: 'sum'}).sort_values(weight_column, ascending=False)\n",
    "                df2['authtrans_vts_cnt']=((df2[weight_column])/df2[weight_column].sum()).round(2)\n",
    "                unq.append(df2.head(n=100).to_dict()[weight_column])\n",
    "            else:\n",
    "                df_cat_d = df[x].value_counts(normalize=normalize_ind,dropna=dropna).round(decimals=2)\n",
    "                df_cat_d = df_cat_d[df_cat_d>0]\n",
    "                #unq.append(df[x].value_counts().iloc[0:100].to_dict())\n",
    "                unq.append(df_cat_d.iloc[0:100].to_dict())\n",
    "            \n",
    "    levels = pd.DataFrame( { 'A_Variable' : var , 'Levels' : l , 'Datatype' : t ,\n",
    "                             'Min Length' : min_l,\n",
    "                             'Max Length': max_l,\n",
    "                             'Level_Values' : unq} )\n",
    "    #levels.sort_values( by = 'Levels' , inplace = True )\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9844723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (800255, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>APPLETON</td>\n",
       "      <td>WI</td>\n",
       "      <td>59414</td>\n",
       "      <td>ASSOCIATED BANK NATL ASSOC</td>\n",
       "      <td>WI</td>\n",
       "      <td>321918</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>WEATHERFORD</td>\n",
       "      <td>TX</td>\n",
       "      <td>76086</td>\n",
       "      <td>REGIONS BANK</td>\n",
       "      <td>AL</td>\n",
       "      <td>621391</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>124270.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>SC</td>\n",
       "      <td>29505</td>\n",
       "      <td>SUPERIOR FINANCIAL GROUP, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>236220</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BOSTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2124</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>236115</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>73100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>37500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LAFAYETTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>47904</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>800250</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>45014</td>\n",
       "      <td>ACCESS BUS. DEVEL &amp; FINANCE IN</td>\n",
       "      <td>OH</td>\n",
       "      <td>235920</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>800251</td>\n",
       "      <td>COHOES</td>\n",
       "      <td>NY</td>\n",
       "      <td>12047</td>\n",
       "      <td>EMPIRE ST. CERT. DEVEL CORP</td>\n",
       "      <td>NY</td>\n",
       "      <td>541430</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>800252</td>\n",
       "      <td>MANSFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>2048</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>722320</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>800253</td>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>7057</td>\n",
       "      <td>VALLEY NATIONAL BANK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>447110</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>800254</td>\n",
       "      <td>CLEVELAND</td>\n",
       "      <td>OH</td>\n",
       "      <td>44115</td>\n",
       "      <td>UNITED MIDWEST SAVINGS BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>722110</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>384750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index         City State    Zip                            Bank  \\\n",
       "0            0     APPLETON    WI  59414      ASSOCIATED BANK NATL ASSOC   \n",
       "1            1  WEATHERFORD    TX  76086                    REGIONS BANK   \n",
       "2            2     FLORENCE    SC  29505   SUPERIOR FINANCIAL GROUP, LLC   \n",
       "3            3       BOSTON    MA   2124        CITIZENS BANK NATL ASSOC   \n",
       "4            4    LAFAYETTE    IN  47904    THE HUNTINGTON NATIONAL BANK   \n",
       "...        ...          ...   ...    ...                             ...   \n",
       "800250  800250    FAIRFIELD    OH  45014  ACCESS BUS. DEVEL & FINANCE IN   \n",
       "800251  800251       COHOES    NY  12047     EMPIRE ST. CERT. DEVEL CORP   \n",
       "800252  800252    MANSFIELD    MA   2048      BANK OF AMERICA NATL ASSOC   \n",
       "800253  800253   WALLINGTON    NJ   7057            VALLEY NATIONAL BANK   \n",
       "800254  800254    CLEVELAND    OH  44115     UNITED MIDWEST SAVINGS BANK   \n",
       "\n",
       "       BankState   NAICS  NoEmp  NewExist  CreateJob  RetainedJob  \\\n",
       "0             WI  321918     26       1.0          0            0   \n",
       "1             AL  621391      2       1.0          1            3   \n",
       "2             CA  236220      3       1.0          3            3   \n",
       "3             RI  236115      5       1.0          0            5   \n",
       "4             OH       0     82       1.0          0            0   \n",
       "...          ...     ...    ...       ...        ...          ...   \n",
       "800250        OH  235920      3       1.0          5            0   \n",
       "800251        NY  541430     10       1.0          0            1   \n",
       "800252        RI  722320      3       1.0          0            3   \n",
       "800253        NJ  447110      3       1.0          3            3   \n",
       "800254        OH  722110     47       1.0          0            0   \n",
       "\n",
       "        FranchiseCode  UrbanRural RevLineCr LowDoc  DisbursementGross  \\\n",
       "0                   1           0         0      N           100000.0   \n",
       "1                   0           1         N      N           146200.0   \n",
       "2                   0           1         N      N            20000.0   \n",
       "3                   1           1         N      N            73100.0   \n",
       "4                   1           0         N      Y            80000.0   \n",
       "...               ...         ...       ...    ...                ...   \n",
       "800250              1           0         N      N           145000.0   \n",
       "800251              1           1         0      N           198000.0   \n",
       "800252              1           1         0      N            10000.0   \n",
       "800253              1           1         0      N           520000.0   \n",
       "800254              1           1         N      N           513000.0   \n",
       "\n",
       "        BalanceGross    GrAppv  SBA_Appv  MIS_Status  \n",
       "0                0.0  100000.0   80000.0           0  \n",
       "1                0.0  146200.0  124270.0           0  \n",
       "2                0.0   20000.0   17000.0           1  \n",
       "3                0.0   75000.0   37500.0           1  \n",
       "4                0.0   80000.0   64000.0           0  \n",
       "...              ...       ...       ...         ...  \n",
       "800250           0.0  145000.0  145000.0           0  \n",
       "800251           0.0  198000.0  198000.0           0  \n",
       "800252           0.0   10000.0    5000.0           1  \n",
       "800253           0.0  520000.0  390000.0           0  \n",
       "800254           0.0  513000.0  384750.0           0  \n",
       "\n",
       "[800255 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('C:/Users/koppu/Downloads/Project 1/SBA_loans_project_1.csv')\n",
    "print(\"Data shape:\", data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005fb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider rows without missing values in target column mis_status\n",
    "data= data.query('MIS_Status != \"Missing\"')\n",
    "\n",
    "# Remove index column\n",
    "data.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c848b4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPLETON</td>\n",
       "      <td>WI</td>\n",
       "      <td>59414</td>\n",
       "      <td>ASSOCIATED BANK NATL ASSOC</td>\n",
       "      <td>WI</td>\n",
       "      <td>321918</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WEATHERFORD</td>\n",
       "      <td>TX</td>\n",
       "      <td>76086</td>\n",
       "      <td>REGIONS BANK</td>\n",
       "      <td>AL</td>\n",
       "      <td>621391</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>124270.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>SC</td>\n",
       "      <td>29505</td>\n",
       "      <td>SUPERIOR FINANCIAL GROUP, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>236220</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOSTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2124</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>236115</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>73100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>37500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAFAYETTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>47904</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>45014</td>\n",
       "      <td>ACCESS BUS. DEVEL &amp; FINANCE IN</td>\n",
       "      <td>OH</td>\n",
       "      <td>235920</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>COHOES</td>\n",
       "      <td>NY</td>\n",
       "      <td>12047</td>\n",
       "      <td>EMPIRE ST. CERT. DEVEL CORP</td>\n",
       "      <td>NY</td>\n",
       "      <td>541430</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>MANSFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>2048</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>722320</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>7057</td>\n",
       "      <td>VALLEY NATIONAL BANK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>447110</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>CLEVELAND</td>\n",
       "      <td>OH</td>\n",
       "      <td>44115</td>\n",
       "      <td>UNITED MIDWEST SAVINGS BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>722110</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>384750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               City State    Zip                            Bank BankState  \\\n",
       "0          APPLETON    WI  59414      ASSOCIATED BANK NATL ASSOC        WI   \n",
       "1       WEATHERFORD    TX  76086                    REGIONS BANK        AL   \n",
       "2          FLORENCE    SC  29505   SUPERIOR FINANCIAL GROUP, LLC        CA   \n",
       "3            BOSTON    MA   2124        CITIZENS BANK NATL ASSOC        RI   \n",
       "4         LAFAYETTE    IN  47904    THE HUNTINGTON NATIONAL BANK        OH   \n",
       "...             ...   ...    ...                             ...       ...   \n",
       "800250    FAIRFIELD    OH  45014  ACCESS BUS. DEVEL & FINANCE IN        OH   \n",
       "800251       COHOES    NY  12047     EMPIRE ST. CERT. DEVEL CORP        NY   \n",
       "800252    MANSFIELD    MA   2048      BANK OF AMERICA NATL ASSOC        RI   \n",
       "800253   WALLINGTON    NJ   7057            VALLEY NATIONAL BANK        NJ   \n",
       "800254    CLEVELAND    OH  44115     UNITED MIDWEST SAVINGS BANK        OH   \n",
       "\n",
       "         NAICS  NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
       "0       321918     26       1.0          0            0              1   \n",
       "1       621391      2       1.0          1            3              0   \n",
       "2       236220      3       1.0          3            3              0   \n",
       "3       236115      5       1.0          0            5              1   \n",
       "4            0     82       1.0          0            0              1   \n",
       "...        ...    ...       ...        ...          ...            ...   \n",
       "800250  235920      3       1.0          5            0              1   \n",
       "800251  541430     10       1.0          0            1              1   \n",
       "800252  722320      3       1.0          0            3              1   \n",
       "800253  447110      3       1.0          3            3              1   \n",
       "800254  722110     47       1.0          0            0              1   \n",
       "\n",
       "        UrbanRural RevLineCr LowDoc  DisbursementGross  BalanceGross  \\\n",
       "0                0         0      N           100000.0           0.0   \n",
       "1                1         N      N           146200.0           0.0   \n",
       "2                1         N      N            20000.0           0.0   \n",
       "3                1         N      N            73100.0           0.0   \n",
       "4                0         N      Y            80000.0           0.0   \n",
       "...            ...       ...    ...                ...           ...   \n",
       "800250           0         N      N           145000.0           0.0   \n",
       "800251           1         0      N           198000.0           0.0   \n",
       "800252           1         0      N            10000.0           0.0   \n",
       "800253           1         0      N           520000.0           0.0   \n",
       "800254           1         N      N           513000.0           0.0   \n",
       "\n",
       "          GrAppv  SBA_Appv  MIS_Status  \n",
       "0       100000.0   80000.0           0  \n",
       "1       146200.0  124270.0           0  \n",
       "2        20000.0   17000.0           1  \n",
       "3        75000.0   37500.0           1  \n",
       "4        80000.0   64000.0           0  \n",
       "...          ...       ...         ...  \n",
       "800250  145000.0  145000.0           0  \n",
       "800251  198000.0  198000.0           0  \n",
       "800252   10000.0    5000.0           1  \n",
       "800253  520000.0  390000.0           0  \n",
       "800254  513000.0  384750.0           0  \n",
       "\n",
       "[800255 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73475d75",
   "metadata": {},
   "source": [
    "## Dataset preparation and clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd73551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace encode Na/Null values\n",
    "data.fillna(0, inplace=True)\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fefe0d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                  object\n",
       "State                 object\n",
       "Zip                    int64\n",
       "Bank                  object\n",
       "BankState             object\n",
       "NAICS                  int64\n",
       "NoEmp                  int64\n",
       "NewExist             float64\n",
       "CreateJob              int64\n",
       "RetainedJob            int64\n",
       "FranchiseCode          int64\n",
       "UrbanRural             int64\n",
       "RevLineCr             object\n",
       "LowDoc                object\n",
       "DisbursementGross    float64\n",
       "BalanceGross         float64\n",
       "GrAppv               float64\n",
       "SBA_Appv             float64\n",
       "MIS_Status             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b774a824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_Variable</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Datatype</th>\n",
       "      <th>Min Length</th>\n",
       "      <th>Max Length</th>\n",
       "      <th>Level_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>31091</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'LOS ANGELES': 10265, 'HOUSTON': 9166, 'NEW Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>52</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'CA': 116234, 'TX': 62648, 'NY': 51520, 'FL':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zip</td>\n",
       "      <td>32655</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{10001: 843, 90015: 816, 93401: 702, 90010: 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bank</td>\n",
       "      <td>5691</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'BANK OF AMERICA NATL ASSOC': 77280, 'WELLS F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BankState</td>\n",
       "      <td>56</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'CA': 105036, 'NC': 70727, 'IL': 58662, 'OH':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NAICS</td>\n",
       "      <td>1306</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 179808, 722110: 24960, 722211: 17305, 8111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoEmp</td>\n",
       "      <td>579</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{1: 137210, 2: 123131, 3: 80793, 4: 65687, 5: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NewExist</td>\n",
       "      <td>3</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{1.0: 573786, 2.0: 225426, 0.0: 1043}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CreateJob</td>\n",
       "      <td>230</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 560211, 1: 56249, 2: 51419, 3: 25670, 4: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RetainedJob</td>\n",
       "      <td>346</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 392105, 1: 78963, 2: 68443, 3: 44463, 4: 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FranchiseCode</td>\n",
       "      <td>2683</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{1: 568329, 0: 185783, 78760: 2988, 68020: 170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UrbanRural</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 418792, 0: 287637, 2: 93826}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RevLineCr</td>\n",
       "      <td>18</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'N': 374209, '0': 229202, 'Y': 179202, 'T': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LowDoc</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'N': 696572, 'Y': 98366, 0: 2296, '0': 1310, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DisbursementGross</td>\n",
       "      <td>109860</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{50000.0: 38939, 100000.0: 32679, 25000.0: 243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BalanceGross</td>\n",
       "      <td>13</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>{0.0: 800243, 115820.0: 1, 96908.0: 1, 43127.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GrAppv</td>\n",
       "      <td>20615</td>\n",
       "      <td>float64</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>{50000.0: 61710, 25000.0: 45606, 100000.0: 453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SBA_Appv</td>\n",
       "      <td>35681</td>\n",
       "      <td>float64</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>{25000.0: 44045, 12500.0: 35731, 5000.0: 27613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MIS_Status</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 660075, 1: 140180}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A_Variable  Levels Datatype  Min Length  Max Length  \\\n",
       "0                City   31091   object           1          30   \n",
       "1               State      52   object           1           2   \n",
       "2                 Zip   32655    int64           1           5   \n",
       "3                Bank    5691   object           1          30   \n",
       "4           BankState      56   object           1           2   \n",
       "5               NAICS    1306    int64           1           6   \n",
       "6               NoEmp     579    int64           1           4   \n",
       "7            NewExist       3  float64           3           3   \n",
       "8           CreateJob     230    int64           1           4   \n",
       "9         RetainedJob     346    int64           1           4   \n",
       "10      FranchiseCode    2683    int64           1           5   \n",
       "11         UrbanRural       3    int64           1           1   \n",
       "12          RevLineCr      18   object           1           1   \n",
       "13             LowDoc       9   object           1           1   \n",
       "14  DisbursementGross  109860  float64           3          10   \n",
       "15       BalanceGross      13  float64           3           8   \n",
       "16             GrAppv   20615  float64           5           9   \n",
       "17           SBA_Appv   35681  float64           5           9   \n",
       "18         MIS_Status       2    int64           1           1   \n",
       "\n",
       "                                         Level_Values  \n",
       "0   {'LOS ANGELES': 10265, 'HOUSTON': 9166, 'NEW Y...  \n",
       "1   {'CA': 116234, 'TX': 62648, 'NY': 51520, 'FL':...  \n",
       "2   {10001: 843, 90015: 816, 93401: 702, 90010: 64...  \n",
       "3   {'BANK OF AMERICA NATL ASSOC': 77280, 'WELLS F...  \n",
       "4   {'CA': 105036, 'NC': 70727, 'IL': 58662, 'OH':...  \n",
       "5   {0: 179808, 722110: 24960, 722211: 17305, 8111...  \n",
       "6   {1: 137210, 2: 123131, 3: 80793, 4: 65687, 5: ...  \n",
       "7               {1.0: 573786, 2.0: 225426, 0.0: 1043}  \n",
       "8   {0: 560211, 1: 56249, 2: 51419, 3: 25670, 4: 1...  \n",
       "9   {0: 392105, 1: 78963, 2: 68443, 3: 44463, 4: 3...  \n",
       "10  {1: 568329, 0: 185783, 78760: 2988, 68020: 170...  \n",
       "11                   {1: 418792, 0: 287637, 2: 93826}  \n",
       "12  {'N': 374209, '0': 229202, 'Y': 179202, 'T': 1...  \n",
       "13  {'N': 696572, 'Y': 98366, 0: 2296, '0': 1310, ...  \n",
       "14  {50000.0: 38939, 100000.0: 32679, 25000.0: 243...  \n",
       "15  {0.0: 800243, 115820.0: 1, 96908.0: 1, 43127.0...  \n",
       "16  {50000.0: 61710, 25000.0: 45606, 100000.0: 453...  \n",
       "17  {25000.0: 44045, 12500.0: 35731, 5000.0: 27613...  \n",
       "18                             {0: 660075, 1: 140180}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df1 = describe_more(data)\n",
    "desc_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942667b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace null values for string data type columns\n",
    "string_cols_names = data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "for col in string_cols_names:\n",
    "    data[col].fillna('Missing',inplace= True)\n",
    "    \n",
    "# Replace null values for float data type columns\n",
    "float_cols_names= data.select_dtypes(include='float').columns.tolist()\n",
    "\n",
    "for col in float_cols_names:\n",
    "    data[col]=data[col].fillna(data[col].mode()[0])\n",
    "    \n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67343e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPLETON</td>\n",
       "      <td>WI</td>\n",
       "      <td>59414</td>\n",
       "      <td>ASSOCIATED BANK NATL ASSOC</td>\n",
       "      <td>WI</td>\n",
       "      <td>321918</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WEATHERFORD</td>\n",
       "      <td>TX</td>\n",
       "      <td>76086</td>\n",
       "      <td>REGIONS BANK</td>\n",
       "      <td>AL</td>\n",
       "      <td>621391</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>124270.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>SC</td>\n",
       "      <td>29505</td>\n",
       "      <td>SUPERIOR FINANCIAL GROUP, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>236220</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOSTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2124</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>236115</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>73100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>37500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAFAYETTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>47904</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>45014</td>\n",
       "      <td>ACCESS BUS. DEVEL &amp; FINANCE IN</td>\n",
       "      <td>OH</td>\n",
       "      <td>235920</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>COHOES</td>\n",
       "      <td>NY</td>\n",
       "      <td>12047</td>\n",
       "      <td>EMPIRE ST. CERT. DEVEL CORP</td>\n",
       "      <td>NY</td>\n",
       "      <td>541430</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>MANSFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>2048</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>722320</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>7057</td>\n",
       "      <td>VALLEY NATIONAL BANK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>447110</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>CLEVELAND</td>\n",
       "      <td>OH</td>\n",
       "      <td>44115</td>\n",
       "      <td>UNITED MIDWEST SAVINGS BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>722110</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>384750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               City State    Zip                            Bank BankState  \\\n",
       "0          APPLETON    WI  59414      ASSOCIATED BANK NATL ASSOC        WI   \n",
       "1       WEATHERFORD    TX  76086                    REGIONS BANK        AL   \n",
       "2          FLORENCE    SC  29505   SUPERIOR FINANCIAL GROUP, LLC        CA   \n",
       "3            BOSTON    MA   2124        CITIZENS BANK NATL ASSOC        RI   \n",
       "4         LAFAYETTE    IN  47904    THE HUNTINGTON NATIONAL BANK        OH   \n",
       "...             ...   ...    ...                             ...       ...   \n",
       "800250    FAIRFIELD    OH  45014  ACCESS BUS. DEVEL & FINANCE IN        OH   \n",
       "800251       COHOES    NY  12047     EMPIRE ST. CERT. DEVEL CORP        NY   \n",
       "800252    MANSFIELD    MA   2048      BANK OF AMERICA NATL ASSOC        RI   \n",
       "800253   WALLINGTON    NJ   7057            VALLEY NATIONAL BANK        NJ   \n",
       "800254    CLEVELAND    OH  44115     UNITED MIDWEST SAVINGS BANK        OH   \n",
       "\n",
       "         NAICS  NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
       "0       321918     26       1.0          0            0              1   \n",
       "1       621391      2       1.0          1            3              0   \n",
       "2       236220      3       1.0          3            3              0   \n",
       "3       236115      5       1.0          0            5              1   \n",
       "4            0     82       1.0          0            0              1   \n",
       "...        ...    ...       ...        ...          ...            ...   \n",
       "800250  235920      3       1.0          5            0              1   \n",
       "800251  541430     10       1.0          0            1              1   \n",
       "800252  722320      3       1.0          0            3              1   \n",
       "800253  447110      3       1.0          3            3              1   \n",
       "800254  722110     47       1.0          0            0              1   \n",
       "\n",
       "        UrbanRural RevLineCr LowDoc  DisbursementGross  BalanceGross  \\\n",
       "0                0         0      N           100000.0           0.0   \n",
       "1                1         N      N           146200.0           0.0   \n",
       "2                1         N      N            20000.0           0.0   \n",
       "3                1         N      N            73100.0           0.0   \n",
       "4                0         N      Y            80000.0           0.0   \n",
       "...            ...       ...    ...                ...           ...   \n",
       "800250           0         N      N           145000.0           0.0   \n",
       "800251           1         0      N           198000.0           0.0   \n",
       "800252           1         0      N            10000.0           0.0   \n",
       "800253           1         0      N           520000.0           0.0   \n",
       "800254           1         N      N           513000.0           0.0   \n",
       "\n",
       "          GrAppv  SBA_Appv  MIS_Status  \n",
       "0       100000.0   80000.0           0  \n",
       "1       146200.0  124270.0           0  \n",
       "2        20000.0   17000.0           1  \n",
       "3        75000.0   37500.0           1  \n",
       "4        80000.0   64000.0           0  \n",
       "...          ...       ...         ...  \n",
       "800250  145000.0  145000.0           0  \n",
       "800251  198000.0  198000.0           0  \n",
       "800252   10000.0    5000.0           1  \n",
       "800253  520000.0  390000.0           0  \n",
       "800254  513000.0  384750.0           0  \n",
       "\n",
       "[800255 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f21dcf",
   "metadata": {},
   "source": [
    "### Categorical and numerical variables encoding\n",
    "\n",
    "Encode categorical variables using either one of the techniques below. Don't use LabelEncoder.\n",
    "- One-hot-encoder for variables with less than 10 valid values. Name your new columns \"Original_name\"_valid_value. If you drop one of the columns, make it clear what valid value is reference value.\n",
    "- Target encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_trg\n",
    "- WOE encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_woe\n",
    "\n",
    "\n",
    "WOE encoder can be used with numerical variables too. \n",
    "\n",
    "\n",
    "Example of use for target encoder:\n",
    "```\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=[...])\n",
    "\n",
    "encoder.fit(X, y)\n",
    "X_cleaned = encoder.transform(X_dirty)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaca1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for categorical columns with fewer than 10 valid values. The column 'LowDoc' is the only categorical variable with 9 levels.\n",
    "import category_encoders as ce\n",
    "one_hot_cols = [col for col in data.columns if data[col].dtype=='object' and data[col].nunique() < 10 and col != 'MIS_Status']\n",
    "one_hot_encoder = ce.OneHotEncoder(cols=one_hot_cols, use_cat_names=True)\n",
    "data = one_hot_encoder.fit_transform(data)\n",
    "\n",
    "encoded_columns=['LowDoc_N','LowDoc_Y','LowDoc_A','LowDoc_Missing','LowDoc_R','LowDoc_0','LowDoc_S','LowDoc_C','LowDoc_1']\n",
    "\n",
    "# For other variables, apply Weight of Evidence (WOE) encoding.\n",
    "woe_cols = [col for col in data.columns if (data[col].dtype=='object'or data[col].dtype=='float64' or data[col].dtype=='int64') and col not in encoded_columns and  col not in one_hot_cols and col != 'MIS_Status']\n",
    "woe_encoder = ce.WOEEncoder(cols=woe_cols)\n",
    "data = woe_encoder.fit_transform(data, data['MIS_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13039e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc_N</th>\n",
       "      <th>LowDoc_Y</th>\n",
       "      <th>LowDoc_S</th>\n",
       "      <th>LowDoc_0</th>\n",
       "      <th>LowDoc_A</th>\n",
       "      <th>LowDoc_0#</th>\n",
       "      <th>LowDoc_C</th>\n",
       "      <th>LowDoc_R</th>\n",
       "      <th>LowDoc_1</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.807410</td>\n",
       "      <td>-0.447333</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>-0.520553</td>\n",
       "      <td>-0.473117</td>\n",
       "      <td>0.215306</td>\n",
       "      <td>-0.770295</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>-0.133985</td>\n",
       "      <td>-0.692692</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>-1.021032</td>\n",
       "      <td>-0.192824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.215542</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.098067</td>\n",
       "      <td>-0.920801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.260044</td>\n",
       "      <td>0.087799</td>\n",
       "      <td>-0.647810</td>\n",
       "      <td>-0.849989</td>\n",
       "      <td>-0.345658</td>\n",
       "      <td>-0.990943</td>\n",
       "      <td>0.194717</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>0.698110</td>\n",
       "      <td>0.633533</td>\n",
       "      <td>0.891946</td>\n",
       "      <td>0.418843</td>\n",
       "      <td>-0.216134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268481</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.450803</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001527</td>\n",
       "      <td>0.190119</td>\n",
       "      <td>1.367093</td>\n",
       "      <td>2.524767</td>\n",
       "      <td>0.285669</td>\n",
       "      <td>0.595189</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>0.348225</td>\n",
       "      <td>0.633533</td>\n",
       "      <td>0.891946</td>\n",
       "      <td>0.418843</td>\n",
       "      <td>-0.216134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363722</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.543111</td>\n",
       "      <td>1.646689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.347705</td>\n",
       "      <td>-0.365121</td>\n",
       "      <td>-0.170371</td>\n",
       "      <td>0.251205</td>\n",
       "      <td>0.148067</td>\n",
       "      <td>1.113878</td>\n",
       "      <td>0.094505</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>-0.133985</td>\n",
       "      <td>0.547686</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>0.418843</td>\n",
       "      <td>-0.216134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.061165</td>\n",
       "      <td>0.408705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.380766</td>\n",
       "      <td>-0.005536</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>-0.333162</td>\n",
       "      <td>-0.122920</td>\n",
       "      <td>-0.851992</td>\n",
       "      <td>-1.727730</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>-0.133985</td>\n",
       "      <td>-0.692692</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>-1.021032</td>\n",
       "      <td>-0.216134</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.409305</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.263511</td>\n",
       "      <td>-0.919279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>-0.042266</td>\n",
       "      <td>-0.083863</td>\n",
       "      <td>-0.270918</td>\n",
       "      <td>-3.392228</td>\n",
       "      <td>-0.122920</td>\n",
       "      <td>-1.005624</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>0.082463</td>\n",
       "      <td>-0.692692</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>-1.021032</td>\n",
       "      <td>-0.216134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.571550</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.628326</td>\n",
       "      <td>-1.663730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>-0.396495</td>\n",
       "      <td>0.154559</td>\n",
       "      <td>-0.530027</td>\n",
       "      <td>-5.563727</td>\n",
       "      <td>-0.048615</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>-0.195806</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>-0.133985</td>\n",
       "      <td>0.695263</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>0.418843</td>\n",
       "      <td>-0.192824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.724560</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-1.031884</td>\n",
       "      <td>-0.676080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>0.036010</td>\n",
       "      <td>-0.365121</td>\n",
       "      <td>-0.225537</td>\n",
       "      <td>0.583805</td>\n",
       "      <td>0.148067</td>\n",
       "      <td>0.743964</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>-0.133985</td>\n",
       "      <td>0.633533</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>0.418843</td>\n",
       "      <td>-0.192824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574206</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.455481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>0.760958</td>\n",
       "      <td>0.173318</td>\n",
       "      <td>0.760958</td>\n",
       "      <td>-0.387738</td>\n",
       "      <td>-0.749115</td>\n",
       "      <td>0.014352</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>0.348225</td>\n",
       "      <td>0.633533</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>0.418843</td>\n",
       "      <td>-0.192824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.530027</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.543820</td>\n",
       "      <td>-0.519840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>0.062024</td>\n",
       "      <td>-0.083863</td>\n",
       "      <td>-0.530027</td>\n",
       "      <td>-0.600407</td>\n",
       "      <td>-0.122920</td>\n",
       "      <td>0.381547</td>\n",
       "      <td>-1.255726</td>\n",
       "      <td>-0.03107</td>\n",
       "      <td>-0.133985</td>\n",
       "      <td>-0.692692</td>\n",
       "      <td>-0.416878</td>\n",
       "      <td>0.418843</td>\n",
       "      <td>-0.216134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.764220</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.563549</td>\n",
       "      <td>-0.278712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State       Zip      Bank  BankState     NAICS     NoEmp  \\\n",
       "0      -0.807410 -0.447333 -0.155333 -0.520553  -0.473117  0.215306 -0.770295   \n",
       "1      -0.260044  0.087799 -0.647810 -0.849989  -0.345658 -0.990943  0.194717   \n",
       "2      -0.001527  0.190119  1.367093  2.524767   0.285669  0.595189  0.192185   \n",
       "3      -0.347705 -0.365121 -0.170371  0.251205   0.148067  1.113878  0.094505   \n",
       "4      -0.380766 -0.005536  0.163121 -0.333162  -0.122920 -0.851992 -1.727730   \n",
       "...          ...       ...       ...       ...        ...       ...       ...   \n",
       "800250 -0.042266 -0.083863 -0.270918 -3.392228  -0.122920 -1.005624  0.192185   \n",
       "800251 -0.396495  0.154559 -0.530027 -5.563727  -0.048615  0.008804 -0.195806   \n",
       "800252  0.036010 -0.365121 -0.225537  0.583805   0.148067  0.743964  0.192185   \n",
       "800253  0.760958  0.173318  0.760958 -0.387738  -0.749115  0.014352  0.192185   \n",
       "800254  0.062024 -0.083863 -0.530027 -0.600407  -0.122920  0.381547 -1.255726   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "0       -0.03107  -0.133985    -0.692692      -0.416878   -1.021032   \n",
       "1       -0.03107   0.698110     0.633533       0.891946    0.418843   \n",
       "2       -0.03107   0.348225     0.633533       0.891946    0.418843   \n",
       "3       -0.03107  -0.133985     0.547686      -0.416878    0.418843   \n",
       "4       -0.03107  -0.133985    -0.692692      -0.416878   -1.021032   \n",
       "...          ...        ...          ...            ...         ...   \n",
       "800250  -0.03107   0.082463    -0.692692      -0.416878   -1.021032   \n",
       "800251  -0.03107  -0.133985     0.695263      -0.416878    0.418843   \n",
       "800252  -0.03107  -0.133985     0.633533      -0.416878    0.418843   \n",
       "800253  -0.03107   0.348225     0.633533      -0.416878    0.418843   \n",
       "800254  -0.03107  -0.133985    -0.692692      -0.416878    0.418843   \n",
       "\n",
       "        RevLineCr  LowDoc_N  LowDoc_Y  LowDoc_S  LowDoc_0  LowDoc_A  \\\n",
       "0       -0.192824         1         0         0         0         0   \n",
       "1       -0.216134         1         0         0         0         0   \n",
       "2       -0.216134         1         0         0         0         0   \n",
       "3       -0.216134         1         0         0         0         0   \n",
       "4       -0.216134         0         1         0         0         0   \n",
       "...           ...       ...       ...       ...       ...       ...   \n",
       "800250  -0.216134         1         0         0         0         0   \n",
       "800251  -0.192824         1         0         0         0         0   \n",
       "800252  -0.192824         1         0         0         0         0   \n",
       "800253  -0.192824         1         0         0         0         0   \n",
       "800254  -0.216134         1         0         0         0         0   \n",
       "\n",
       "        LowDoc_0#  LowDoc_C  LowDoc_R  LowDoc_1  DisbursementGross  \\\n",
       "0        -0.00419         0         0         0          -0.215542   \n",
       "1        -0.00419         0         0         0           0.268481   \n",
       "2        -0.00419         0         0         0           0.363722   \n",
       "3        -0.00419         0         0         0           0.163121   \n",
       "4        -0.00419         0         0         0          -0.409305   \n",
       "...           ...       ...       ...       ...                ...   \n",
       "800250   -0.00419         0         0         0          -0.571550   \n",
       "800251   -0.00419         0         0         0          -0.724560   \n",
       "800252   -0.00419         0         0         0           0.574206   \n",
       "800253   -0.00419         0         0         0          -0.530027   \n",
       "800254   -0.00419         0         0         0          -0.764220   \n",
       "\n",
       "        BalanceGross    GrAppv  SBA_Appv  MIS_Status  \n",
       "0           0.000013  0.098067 -0.920801           0  \n",
       "1           0.000013  0.450803  0.163121           0  \n",
       "2           0.000013  0.543111  1.646689           1  \n",
       "3           0.000013  0.061165  0.408705           1  \n",
       "4           0.000013 -0.263511 -0.919279           0  \n",
       "...              ...       ...       ...         ...  \n",
       "800250      0.000013 -0.628326 -1.663730           0  \n",
       "800251      0.000013 -1.031884 -0.676080           0  \n",
       "800252      0.000013  0.651316  0.455481           1  \n",
       "800253      0.000013 -0.543820 -0.519840           0  \n",
       "800254      0.000013 -0.563549 -0.278712           0  \n",
       "\n",
       "[800255 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefaf432",
   "metadata": {},
   "source": [
    "**Summary: Data Preprocessing**\n",
    "\n",
    "In the preprocessing stage, I have refined the dataset for model readiness, addressing missing values and implementing categorical variable encoding through one-hot and Weight of Evidence (WOE) techniques. These steps ensured the data was in an optimal state, enriching its structure and potentially enhancing model interpretability and accuracy. Although specific model performance metrics from this phase weren't detailed, the preparation likely set a solid foundation for effective learning and prediction. \n",
    "\n",
    "From this groundwork, I recommend an iterative approach to feature engineering to continuously uncover impactful predictors. Diversifying modeling techniques could further improve predictive accuracy. Implementing rigorous validation strategies will help ascertain the model's robustness across different data subsets. Finally, once the model is deployed, establishing a routine for its performance monitoring is crucial to adapt to new data and maintain its predictive quality. This structured approach to data preprocessing and strategic model development forms the cornerstone of our endeavor to predict outcomes with higher precision and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b0150",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83dd9f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((402127, 26), (402127, 1)), Validation set shape: ((198064, 26), (198064, 1)), Test set shape: ((200064, 26), (200064, 1))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, test, validation set \n",
    "X = data.drop(columns=['MIS_Status'])\n",
    "Y = data[['MIS_Status']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr_temp, X_test, y_tr_temp, y_test = train_test_split(X, Y, test_size=0.25, random_state=33)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tr_temp, y_tr_temp, test_size=0.33, random_state=33)\n",
    "\n",
    "train_shape = X_train.shape, y_train.shape\n",
    "val_shape = X_valid.shape, y_valid.shape\n",
    "test_shape = X_test.shape, y_test.shape\n",
    "\n",
    "print('Training set shape: {}, Validation set shape: {}, Test set shape: {}'.format(train_shape, val_shape, test_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5adf73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns with '_woe' appended at the end.\n",
    "# Define a dictionary to map original column names to their corresponding new names.\n",
    "column_names = {\n",
    "    'City': 'City_woe',\n",
    "    'State': 'State_woe',\n",
    "    'Bank': 'Bank_woe',\n",
    "    'BankState': 'Bankstate_woe',\n",
    "    'RevLineCr': 'RevLinecr_woe',\n",
    "    'Zip':'Zip_woe',\n",
    "    'NAICS':'NAICS_woe',\n",
    "    'NoEmp':'NoEmp_woe',\n",
    "    'NewExist':'NewExist_woe',\n",
    "    'CreateJob':'CreateJob_woe',\n",
    "    'RetainedJob':'RetainedJob_woe',\n",
    "    'FranchiseCode':'FranchiseCode_woe',\n",
    "    'UrbanRural':'UrbanRural_woe',\n",
    "    'DisbursementGross':'DisbursementGross_woe',\n",
    "    'BalanceGross':'BalanceGross_woe',\n",
    "    'GrAppv':'GrAppv_woe',\n",
    "    'SBA_Appv':'SBA_Appv_woe'\n",
    "}\n",
    "\n",
    "# Iterate through each data frame and rename the columns\n",
    "for df in [X_train, X_test, X_valid]:\n",
    "    df.rename(columns=column_names, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba62f6e",
   "metadata": {},
   "source": [
    "**Summary: Model Training**\n",
    "\n",
    "This phase focused on training the predictive model. This step was crucial, as it involved adjusting the model with our dataset to ensure it accurately predicts future outcomes based on past data. This process is essential for the project's success, as it directly influences the model's effectiveness in providing reliable insights.\n",
    "\n",
    "Utilizing GLM for an additional set of four features derived from the data set. The following five features have been \n",
    "selected for inclusion in the GLM model due to their anticipated significant influence on the loan status, with explanations \n",
    "provided below for each selection:\n",
    "\n",
    "1. SBA_Appv: The portion of the loan guaranteed by the Small Business Administration (SBA) is expected to influence the probability of loan default. \n",
    "2. GrAppv: The total amount of the loan approved by the bank is anticipated to impact the likelihood of loan default. \n",
    "3. UrbanRural: The borrower's location, classified as urban or rural, is expected to affect the likelihood of loan default, attributed to differing economic circumstances and available resources. \n",
    "4. NoEmp: The count of business employees could potentially affect the probability of loan default, with businesses employing more individuals possibly possessing greater resources to fulfill loan obligations.\n",
    "\n",
    "Through this training phase, our model has started to show promising results, demonstrating its capability to uncover patterns within the data that were not immediately apparent. This progress is significant as it moves me closer to our goal of developing a tool that can inform decision-making processes with precision. The work done in these cells lays a solid foundation for the next steps in our project, where I'll refine the model further and explore its application in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced690c6",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "You should tune two types of models: one Sklearn and one H2O-3. Perform tuning for the selected model type from the set of Linear models available in Sklearn and H2O-3:\n",
    "- Hyper-parameter tuning. Your hyper-parameter search space should have at least 50 combinations.\n",
    "- To avoid overfitting and provide you with reasonable estimate of model performance on hold-out dataset, you will need to split your dataset as following:\n",
    "    - Train, will be used to train model\n",
    "    - Validation, will be used to validate model each round of training\n",
    "    - Testing, will be used to provide final performance metrics, used only once on the final model\n",
    "- Feature engineering. See project description\n",
    "\n",
    "**Select final model that produces best performance on the Test dataset.**\n",
    "- For the best model, calculate probability threshold to maximize F1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674ab5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters [0.001, 'l1', 'liblinear'], training data accuracy0.8482494336366372, validation data accuracy 0.8485741982389531\n",
      "parameters [0.001, 'l1', 'newton-cg'], invalid parameters\n",
      "parameters [0.001, 'l1', 'lbfgs'], invalid parameters\n",
      "parameters [0.001, 'l1', 'sag'], invalid parameters\n",
      "parameters [0.001, 'l1', 'saga'], training data accuracy0.8481101741489628, validation data accuracy 0.8484631230309395\n",
      "parameters [0.001, 'l2', 'liblinear'], training data accuracy0.8489581649578367, validation data accuracy 0.8495082397608854\n",
      "parameters [0.001, 'l2', 'newton-cg'], training data accuracy0.8487716567154158, validation data accuracy 0.849331529202682\n",
      "parameters [0.001, 'l2', 'lbfgs'], training data accuracy0.8487741434919814, validation data accuracy 0.8493264803295905\n",
      "parameters [0.001, 'l2', 'sag'], training data accuracy0.8487716567154158, validation data accuracy 0.8493264803295905\n",
      "parameters [0.001, 'l2', 'saga'], training data accuracy0.8487716567154158, validation data accuracy 0.849331529202682\n",
      "parameters [0.001, 'elasticnet', 'liblinear'], invalid parameters\n",
      "parameters [0.001, 'elasticnet', 'newton-cg'], invalid parameters\n",
      "parameters [0.001, 'elasticnet', 'lbfgs'], invalid parameters\n",
      "parameters [0.001, 'elasticnet', 'sag'], invalid parameters\n",
      "parameters [0.001, 'elasticnet', 'saga'], invalid parameters\n",
      "parameters [0.001, 'none', 'liblinear'], invalid parameters\n",
      "parameters [0.001, 'none', 'newton-cg'], training data accuracy0.8491123451049046, validation data accuracy 0.8496445593343566\n",
      "parameters [0.001, 'none', 'lbfgs'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [0.001, 'none', 'sag'], training data accuracy0.8491098583283391, validation data accuracy 0.8496445593343566\n",
      "parameters [0.001, 'none', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [0.015848931924611134, 'l1', 'liblinear'], training data accuracy0.8490949376689454, validation data accuracy 0.8495688262379837\n",
      "parameters [0.015848931924611134, 'l1', 'newton-cg'], invalid parameters\n",
      "parameters [0.015848931924611134, 'l1', 'lbfgs'], invalid parameters\n",
      "parameters [0.015848931924611134, 'l1', 'sag'], invalid parameters\n",
      "parameters [0.015848931924611134, 'l1', 'saga'], training data accuracy0.8491023979986422, validation data accuracy 0.8495738751110752\n",
      "parameters [0.015848931924611134, 'l2', 'liblinear'], training data accuracy0.8491272657642983, validation data accuracy 0.8496445593343566\n",
      "parameters [0.015848931924611134, 'l2', 'newton-cg'], training data accuracy0.8491048847752078, validation data accuracy 0.8496799014459973\n",
      "parameters [0.015848931924611134, 'l2', 'lbfgs'], training data accuracy0.8491048847752078, validation data accuracy 0.8496698036998142\n",
      "parameters [0.015848931924611134, 'l2', 'sag'], training data accuracy0.8491073715517734, validation data accuracy 0.8496748525729058\n",
      "parameters [0.015848931924611134, 'l2', 'saga'], training data accuracy0.8491048847752078, validation data accuracy 0.8496799014459973\n",
      "parameters [0.015848931924611134, 'elasticnet', 'liblinear'], invalid parameters\n",
      "parameters [0.015848931924611134, 'elasticnet', 'newton-cg'], invalid parameters\n",
      "parameters [0.015848931924611134, 'elasticnet', 'lbfgs'], invalid parameters\n",
      "parameters [0.015848931924611134, 'elasticnet', 'sag'], invalid parameters\n",
      "parameters [0.015848931924611134, 'elasticnet', 'saga'], invalid parameters\n",
      "parameters [0.015848931924611134, 'none', 'liblinear'], invalid parameters\n",
      "parameters [0.015848931924611134, 'none', 'newton-cg'], training data accuracy0.8491123451049046, validation data accuracy 0.8496445593343566\n",
      "parameters [0.015848931924611134, 'none', 'lbfgs'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [0.015848931924611134, 'none', 'sag'], training data accuracy0.8491123451049046, validation data accuracy 0.8496395104612651\n",
      "parameters [0.015848931924611134, 'none', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [0.25118864315095796, 'l1', 'liblinear'], training data accuracy0.8491173186580359, validation data accuracy 0.8496647548267227\n",
      "parameters [0.25118864315095796, 'l1', 'newton-cg'], invalid parameters\n",
      "parameters [0.25118864315095796, 'l1', 'lbfgs'], invalid parameters\n",
      "parameters [0.25118864315095796, 'l1', 'sag'], invalid parameters\n",
      "parameters [0.25118864315095796, 'l1', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496546570805397\n",
      "parameters [0.25118864315095796, 'l2', 'liblinear'], training data accuracy0.8490899641158142, validation data accuracy 0.8496597059536312\n",
      "parameters [0.25118864315095796, 'l2', 'newton-cg'], training data accuracy0.8490800170095517, validation data accuracy 0.8496849503190887\n",
      "parameters [0.25118864315095796, 'l2', 'lbfgs'], training data accuracy0.8490849905626829, validation data accuracy 0.8496395104612651\n",
      "parameters [0.25118864315095796, 'l2', 'sag'], training data accuracy0.8490800170095517, validation data accuracy 0.8496849503190887\n",
      "parameters [0.25118864315095796, 'l2', 'saga'], training data accuracy0.8490800170095517, validation data accuracy 0.8496849503190887\n",
      "parameters [0.25118864315095796, 'elasticnet', 'liblinear'], invalid parameters\n",
      "parameters [0.25118864315095796, 'elasticnet', 'newton-cg'], invalid parameters\n",
      "parameters [0.25118864315095796, 'elasticnet', 'lbfgs'], invalid parameters\n",
      "parameters [0.25118864315095796, 'elasticnet', 'sag'], invalid parameters\n",
      "parameters [0.25118864315095796, 'elasticnet', 'saga'], invalid parameters\n",
      "parameters [0.25118864315095796, 'none', 'liblinear'], invalid parameters\n",
      "parameters [0.25118864315095796, 'none', 'newton-cg'], training data accuracy0.8491123451049046, validation data accuracy 0.8496445593343566\n",
      "parameters [0.25118864315095796, 'none', 'lbfgs'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [0.25118864315095796, 'none', 'sag'], training data accuracy0.8491098583283391, validation data accuracy 0.8496496082074481\n",
      "parameters [0.25118864315095796, 'none', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [3.981071705534969, 'l1', 'liblinear'], training data accuracy0.8490999112220766, validation data accuracy 0.8496344615881736\n",
      "parameters [3.981071705534969, 'l1', 'newton-cg'], invalid parameters\n",
      "parameters [3.981071705534969, 'l1', 'lbfgs'], invalid parameters\n",
      "parameters [3.981071705534969, 'l1', 'sag'], invalid parameters\n",
      "parameters [3.981071705534969, 'l1', 'saga'], training data accuracy0.8491048847752078, validation data accuracy 0.8496395104612651\n",
      "parameters [3.981071705534969, 'l2', 'liblinear'], training data accuracy0.8491048847752078, validation data accuracy 0.8496243638419905\n",
      "parameters [3.981071705534969, 'l2', 'newton-cg'], training data accuracy0.8491023979986422, validation data accuracy 0.8496344615881736\n",
      "parameters [3.981071705534969, 'l2', 'lbfgs'], training data accuracy0.8490999112220766, validation data accuracy 0.8496395104612651\n",
      "parameters [3.981071705534969, 'l2', 'sag'], training data accuracy0.8491023979986422, validation data accuracy 0.8496344615881736\n",
      "parameters [3.981071705534969, 'l2', 'saga'], training data accuracy0.8491023979986422, validation data accuracy 0.8496344615881736\n",
      "parameters [3.981071705534969, 'elasticnet', 'liblinear'], invalid parameters\n",
      "parameters [3.981071705534969, 'elasticnet', 'newton-cg'], invalid parameters\n",
      "parameters [3.981071705534969, 'elasticnet', 'lbfgs'], invalid parameters\n",
      "parameters [3.981071705534969, 'elasticnet', 'sag'], invalid parameters\n",
      "parameters [3.981071705534969, 'elasticnet', 'saga'], invalid parameters\n",
      "parameters [3.981071705534969, 'none', 'liblinear'], invalid parameters\n",
      "parameters [3.981071705534969, 'none', 'newton-cg'], training data accuracy0.8491123451049046, validation data accuracy 0.8496445593343566\n",
      "parameters [3.981071705534969, 'none', 'lbfgs'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [3.981071705534969, 'none', 'sag'], training data accuracy0.8491123451049046, validation data accuracy 0.8496445593343566\n",
      "parameters [3.981071705534969, 'none', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'l1', 'liblinear'], training data accuracy0.8491198054346015, validation data accuracy 0.8496496082074481\n",
      "parameters [63.0957344480193, 'l1', 'newton-cg'], invalid parameters\n",
      "parameters [63.0957344480193, 'l1', 'lbfgs'], invalid parameters\n",
      "parameters [63.0957344480193, 'l1', 'sag'], invalid parameters\n",
      "parameters [63.0957344480193, 'l1', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'l2', 'liblinear'], training data accuracy0.8491023979986422, validation data accuracy 0.849629412715082\n",
      "parameters [63.0957344480193, 'l2', 'newton-cg'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'l2', 'lbfgs'], training data accuracy0.8490999112220766, validation data accuracy 0.8496395104612651\n",
      "parameters [63.0957344480193, 'l2', 'sag'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'l2', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'elasticnet', 'liblinear'], invalid parameters\n",
      "parameters [63.0957344480193, 'elasticnet', 'newton-cg'], invalid parameters\n",
      "parameters [63.0957344480193, 'elasticnet', 'lbfgs'], invalid parameters\n",
      "parameters [63.0957344480193, 'elasticnet', 'sag'], invalid parameters\n",
      "parameters [63.0957344480193, 'elasticnet', 'saga'], invalid parameters\n",
      "parameters [63.0957344480193, 'none', 'liblinear'], invalid parameters\n",
      "parameters [63.0957344480193, 'none', 'newton-cg'], training data accuracy0.8491123451049046, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'none', 'lbfgs'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'none', 'sag'], training data accuracy0.8491173186580359, validation data accuracy 0.8496445593343566\n",
      "parameters [63.0957344480193, 'none', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [1000.0, 'l1', 'liblinear'], training data accuracy0.8491173186580359, validation data accuracy 0.8496496082074481\n",
      "parameters [1000.0, 'l1', 'newton-cg'], invalid parameters\n",
      "parameters [1000.0, 'l1', 'lbfgs'], invalid parameters\n",
      "parameters [1000.0, 'l1', 'sag'], invalid parameters\n",
      "parameters [1000.0, 'l1', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [1000.0, 'l2', 'liblinear'], training data accuracy0.8491023979986422, validation data accuracy 0.849629412715082\n",
      "parameters [1000.0, 'l2', 'newton-cg'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [1000.0, 'l2', 'lbfgs'], training data accuracy0.8491023979986422, validation data accuracy 0.8496597059536312\n",
      "parameters [1000.0, 'l2', 'sag'], training data accuracy0.8491098583283391, validation data accuracy 0.8496445593343566\n",
      "parameters [1000.0, 'l2', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [1000.0, 'elasticnet', 'liblinear'], invalid parameters\n",
      "parameters [1000.0, 'elasticnet', 'newton-cg'], invalid parameters\n",
      "parameters [1000.0, 'elasticnet', 'lbfgs'], invalid parameters\n",
      "parameters [1000.0, 'elasticnet', 'sag'], invalid parameters\n",
      "parameters [1000.0, 'elasticnet', 'saga'], invalid parameters\n",
      "parameters [1000.0, 'none', 'liblinear'], invalid parameters\n",
      "parameters [1000.0, 'none', 'newton-cg'], training data accuracy0.8491123451049046, validation data accuracy 0.8496445593343566\n",
      "parameters [1000.0, 'none', 'lbfgs'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "parameters [1000.0, 'none', 'sag'], training data accuracy0.8491148318814703, validation data accuracy 0.8496395104612651\n",
      "parameters [1000.0, 'none', 'saga'], training data accuracy0.8491148318814703, validation data accuracy 0.8496445593343566\n",
      "accuracy score on training dataset: 0.8490800170095517\n",
      "accuracy score on testing dataset: 0.8498480486244402\n",
      "Maximum of F1 values: 0.705011161080092\n",
      "required threshold: 0.32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Create a new DataFrame with X_train and y_train combined\n",
    "train_glm = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Define the formula for the GLM\n",
    "formula = 'MIS_Status ~ SBA_Appv_woe + UrbanRural_woe + NoEmp_woe + GrAppv_woe'\n",
    "\n",
    "# Create and fit the GLM model\n",
    "glm_model = sm.GLM.from_formula(formula=formula, data=train_glm).fit()\n",
    "\n",
    "# Make predictions using the GLM model for the train, validation, and test datasets\n",
    "X_train_glm = glm_model.predict(X_train[['SBA_Appv_woe', 'UrbanRural_woe', 'NoEmp_woe', 'GrAppv_woe']])\n",
    "X_valid_glm = glm_model.predict(X_valid[['SBA_Appv_woe', 'UrbanRural_woe', 'NoEmp_woe', 'GrAppv_woe']])\n",
    "X_test_glm = glm_model.predict(X_test[['SBA_Appv_woe', 'UrbanRural_woe', 'NoEmp_woe', 'GrAppv_woe']])\n",
    "\n",
    "#add the glm columns to the original dataframes\n",
    "def add_glm_columns(dataset, glm_data):\n",
    "    dataset[\"GLM1\"] = glm_data\n",
    "    features = ['SBA_Appv_woe', 'UrbanRural_woe', 'NoEmp_woe', 'GrAppv_woe']\n",
    "    for i, feature in enumerate(features):\n",
    "        dataset[f\"GLM{i+2}\"] = glm_data * dataset[feature]\n",
    "\n",
    "# Add GLM columns to X_train, X_val, and X_test\n",
    "add_glm_columns(X_train, X_train_glm)\n",
    "add_glm_columns(X_valid, X_valid_glm)\n",
    "add_glm_columns(X_test, X_test_glm)\n",
    "\n",
    "#Train logistic regression model \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "#hyperparameter space \n",
    "C = np.logspace(-3,3,6) #parameter to control the inverse of regularization strength\n",
    "penalty = [\"l1\", \"l2\", \"elasticnet\", \"none\"] #no regularization, l1,l2, elasticnet regularizations\n",
    "solver = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "combinations_counter = 0 #counter to keep track of combinations\n",
    "accuracy1 = [] #accuracy 1 --> keep track of training data set, accuracy\n",
    "accuracy2 = [] #accuracy 2 --> keep track of validation data set, accuracy\n",
    "all_params = [] # to store the hyperparameter combinations\n",
    "\n",
    "for l in C:\n",
    "    for m in penalty:\n",
    "        for n in solver:\n",
    "            parameters = [l, m, n]\n",
    "            combinations_counter += 1\n",
    "            try:\n",
    "                logReg = LogisticRegression(C=l, penalty=m, solver=n)\n",
    "                logReg.fit(X_train, y_train)\n",
    "                predict_y_tr = logReg.predict(X_train)\n",
    "                predict_y_valid = logReg.predict(X_valid)\n",
    "                a1 = accuracy_score(y_train, predict_y_tr)\n",
    "                a2 = accuracy_score(y_valid, predict_y_valid)\n",
    "                accuracy1.append(a1)\n",
    "                accuracy2.append(a2)\n",
    "                all_params.append(parameters)\n",
    "                print(f\"parameters {parameters}, training data accuracy{a1}, validation data accuracy {a2}\")\n",
    "            except Exception as e:\n",
    "                print(f\"parameters {parameters}, invalid parameters\")\n",
    "# Here, we select the model that achieved the highest accuracy on the validation set. We do this because the primary objective of the model is to perform effectively on unseen data.\n",
    "# Identify the index where the highest accuracy was attained on the validation dataset\n",
    "index = np.argmax(accuracy2)\n",
    "# Retrieve the parameters corresponding to the identified index\n",
    "best_parameters = all_params[index]\n",
    "# Train a new logistic regression model using the best hyperparameters obtained from the above step\n",
    "logReg = LogisticRegression(C=best_parameters[0], penalty=best_parameters[1], solver=best_parameters[2])\n",
    "logReg.fit(X_train, y_train)\n",
    "predict_y_tr = logReg.predict(X_train)\n",
    "predict_y_tst = logReg.predict(X_test)\n",
    "print(\"accuracy score on training dataset:\", accuracy_score(y_train, predict_y_tr))\n",
    "print(\"accuracy score on testing dataset:\", accuracy_score(y_test, predict_y_tst))\n",
    "\n",
    "predict_y_probability = logReg.predict_proba(X_test)[:, 1] #predict the probability of each instance of y in test set belonging to positive class\n",
    "range_of_t = np.arange(0, 1, 0.01) #define a range of thresholds to calculate f1 score at each theshold\n",
    "f1_values = [f1_score(y_test, predict_y_probability >= t, average='macro') for t in range_of_t]\n",
    "required_threshold = range_of_t[np.argmax(f1_values)]\n",
    "\n",
    "print(\"Maximum of F1 values:\", np.max(f1_values))\n",
    "print(\"required threshold:\", required_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c44af14",
   "metadata": {},
   "source": [
    "**Summary: Model Tuning**\n",
    "\n",
    "Here we are trying to evaluate our model's performance against a test dataset. This evaluation revealed promising outcomes, showcasing the model's ability to generalize well beyond the training data. Notably, our model achieved an accuracy score of 0.849 on the training set and an even slightly higher score of 0.850 on the test set. These metrics indicate a high level of consistency and reliability in the model’s predictions across different data samples. \n",
    "\n",
    "Furthermore, through meticulous testing, I identified an optimal F1 score of 0.705 at a probability threshold of 0.32. This optimal threshold signifies the balance point where our model efficiently harmonizes precision and recall, enhancing its predictive quality for practical applications. The insights garnered from these metrics are invaluable. They not only affirm the model's robustness but also guide our next steps in refining and optimizing the model to better serve its intended decision-making support role, armed with evidence of its effectiveness and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc381c",
   "metadata": {},
   "source": [
    "## Save all artifacts\n",
    "\n",
    "Save all artifacts needed for scoring function:\n",
    "- Trained model\n",
    "- Encoders\n",
    "- Any other arficats you will need for scoring\n",
    "\n",
    "**You should stop your notebook here. Scoring function should be in a separate file/notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f18760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koppu\\Applied Machine Learning\\Project 1\\Latest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6d0a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists('./artifacts3'):\n",
    "    os.makedirs('./artifacts3')\n",
    "\n",
    "pickle.dump(logReg, open('./artifacts3/LogisticRegressionModel.pkl', 'wb'))\n",
    "pickle.dump(one_hot_encoder, open('./artifacts3/one_hot_encoder.pkl', 'wb'))\n",
    "pickle.dump(woe_encoder, open('./artifacts3/woe_encoder.pkl', 'wb'))\n",
    "pickle.dump(glm_model, open('./artifacts3/glm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1861176",
   "metadata": {},
   "source": [
    "## Project Summary and Conclusion\n",
    "\n",
    "Provide your summary and conclusion. The summary should include:\n",
    "- Summary of your work\n",
    "- Summary of your findings\n",
    "- Summary of your model performance\n",
    "- Summary of your recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cf1c67",
   "metadata": {},
   "source": [
    "# Summary and Conclusion:\n",
    "\n",
    "**Summary of Work:**\n",
    "\n",
    "In this project, I undertook comprehensive data preprocessing, model training, and tuning to develop an effective predictive model for loan status determination. The preprocessing stage involved refining the dataset to ensure model readiness by addressing missing values and implementing categorical variable encoding using one-hot and Weight of Evidence (WOE) techniques. Model training encompassed training logistic regression models, including a GLM model with selected features. Additionally, model tuning involved evaluating performance against a test dataset and identifying optimal thresholds for enhancing predictive quality.\n",
    "\n",
    "**Summary of Findings:**\n",
    "\n",
    "Through rigorous analysis, I identified key predictors such as SBA_Appv, GrAppv, UrbanRural, and NoEmp, which significantly influence loan status prediction. The inclusion of GLM models allowed for deeper insights into the dataset, uncovering hidden patterns crucial for accurate predictions.\n",
    "\n",
    "**Summary of Model Performance:**\n",
    "\n",
    "The trained models demonstrated promising performance, exhibiting high accuracy and consistency across training and test datasets. Notably, the models achieved an accuracy score of 0.849 on the training set and a slightly higher score of 0.850 on the test set, indicating robust generalization beyond the training data. Furthermore, the identification of an optimal F1 score at a probability threshold of 0.32 signifies a balanced trade-off between precision and recall, enhancing the model's practical utility.\n",
    "\n",
    "**Summary of Recommendations:**\n",
    "\n",
    "Based on the findings, I recommend further refinement and optimization of the model to enhance its predictive accuracy and robustness. This can be achieved through iterative feature engineering, diversifying modeling techniques, and implementing rigorous validation strategies. Additionally, establishing a routine for model performance monitoring post-deployment is essential to adapt to evolving data and maintain predictive quality over time.\n",
    "\n",
    "Overall, the structured approach to data preprocessing, strategic model development, and meticulous model tuning lays a solid foundation for accurate loan status prediction, facilitating informed decision-making in lending scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556b0fe",
   "metadata": {},
   "source": [
    "## Stop Here. Create new file/notebook\n",
    "\n",
    "Don't include scoring function in the same notebook as your project. Create a new notebook or python file for scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f71c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0d2e830",
   "metadata": {},
   "source": [
    "### Model Scoring\n",
    "\n",
    "Write function that will load artifacts from above, transform and score on a new dataset.\n",
    "Your function should return Python list of labels. For example: [0,1,0,1,1,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1929ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_1_scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return pandas DF with following columns:\n",
    "            - index\n",
    "            - label\n",
    "            - probability_0\n",
    "            - probability_1\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc128b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16157e5c",
   "metadata": {},
   "source": [
    "### Example of Scoring function\n",
    "\n",
    "Don't copy the code as is. It is provided as an example only. \n",
    "- Function `train_model` - you need to focus on model and artifacts saving:\n",
    "    ```\n",
    "    pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
    "    ```\n",
    "- Function `project_1_scoring` - you should have similar function with name `project_1_scoring`. The function will:\n",
    "    - Get Pandas dataframe as parameter\n",
    "    - Will load model and all needed encoders\n",
    "    - Will perform needed manipulations on the input Pandas DF - in the exact same format as input file for the project, minus MIS_Status feature\n",
    "    - Return Pandas DataFrame\n",
    "        - record index\n",
    "        - predicted class for threshold maximizing F1\n",
    "        - probability for class 0 (PIF)\n",
    "        - probability for class 1 (CHGOFF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135cbce",
   "metadata": {},
   "source": [
    "Don't copy the below cell code in any way!!! The code is provided as an example only.  \n",
    "- The code is provided as an example of generating artifacts for scoring function\n",
    "- Your scoring function code should not have model training part!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2847fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Don't copy of use the cell code in any way!!!\n",
    "The code is provided as an example of generating artifacts for scoring function\n",
    "Your scoring function code should not have model training part!!!!\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def train_model(data):\n",
    "    \"\"\"\n",
    "    Train sample model and save artifacts\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from copy import deepcopy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    target_col = \"Survived\"\n",
    "    cols_to_drop = ['Name', 'Ticket', 'Cabin','SibSp', 'Parch', 'Sex','Embarked','PassengerId','Survived']\n",
    "    y = data[target_col]\n",
    "    X = data.drop(columns=[target_col])\n",
    "    \n",
    "    # Impute Embarked\n",
    "    X['Embarked'].replace(np.NaN, 'S',inplace = True)\n",
    "    \n",
    "    # Create new feature\n",
    "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
    "    \n",
    "    # Mean impute Age\n",
    "    imp_age_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_age_mean.fit(X[['Age']])\n",
    "    X['Age'] = imp_age_mean.transform(X[['Age']])\n",
    "\n",
    "\n",
    "    ohe_orig_columns = [\"Embarked\",\"Sex\"]\n",
    "    cat_encoders = {}\n",
    "    for col in ohe_orig_columns:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        enc.fit(X[[col]])\n",
    "        result = enc.transform(X[[col]])\n",
    "        ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
    "        result_train = pd.DataFrame(result, columns=ohe_columns)\n",
    "        X= pd.concat([X, result_train], axis=1)\n",
    "        cat_encoders[col] = [deepcopy(enc),\"ohe\"]\n",
    "        \n",
    "    clf = LogisticRegression(max_iter=1000, random_state=0)\n",
    "    \n",
    "    columns_to_train = [x for x in X.columns if x not in cols_to_drop]\n",
    "    print(\"Training on following columns:\", columns_to_train)\n",
    "    clf.fit(X[columns_to_train], y)\n",
    "    \n",
    "    # Todo: Add code to calculate optimal threshold. Replace 0.5 !!!!!\n",
    "    threshold = 0.5\n",
    "    # End Todo\n",
    "    \n",
    "    artifacts_dict = {\n",
    "        \"model\": clf,\n",
    "        \"cat_encoders\": cat_encoders,\n",
    "        \"imp_age_mean\": imp_age_mean,\n",
    "        \"ohe_columns\": ohe_orig_columns,\n",
    "        \"columns_to_train\":columns_to_train,\n",
    "        \"threshold\": threshold\n",
    "    }\n",
    "    artifacts_dict_file = open(\"./artifacts/artifacts_dict_file.pkl\", \"wb\")\n",
    "    pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
    "    \n",
    "    artifacts_dict_file.close()    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "719dcec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m target_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target_col]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('titanic.csv')\n",
    "target_col = \"Survived\"\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=142)\n",
    "\n",
    "# Reset index to avoid bug with OHE encoder due to index mismatch\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "df_train = X_train.copy()\n",
    "df_train[target_col] = y_train\n",
    "train_model(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88cb35",
   "metadata": {},
   "source": [
    "### Example scoring function\n",
    "\n",
    "This is example only. Don't copy the code as is!!!   \n",
    "You must place scoring function in a separate Python file or Jupyter notebook.   \n",
    "\n",
    "**Don't place function in the same notebook as rest of the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_1_scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return labels\n",
    "    \n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from copy import deepcopy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "    \n",
    "    X = data.copy()\n",
    "    \n",
    "    '''Load Artifacts'''\n",
    "    artifacts_dict_file = open(\"./artifacts/artifacts_dict_file.pkl\", \"rb\")\n",
    "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
    "    artifacts_dict_file.close()\n",
    "    \n",
    "    clf = artifacts_dict[\"model\"]\n",
    "    cat_encoders = artifacts_dict[\"cat_encoders\"]\n",
    "    imp_age_mean = artifacts_dict[\"imp_age_mean\"]\n",
    "    ohe_columns = artifacts_dict[\"ohe_columns\"]\n",
    "    columns_to_score = artifacts_dict[\"columns_to_train\"]\n",
    "    threshold = artifacts_dict[\"threshold\"]\n",
    "    \n",
    "    # Impute Embarked\n",
    "    X['Embarked'].replace(np.NaN, 'S',inplace = True)\n",
    "    \n",
    "    # Create new feature\n",
    "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
    "    \n",
    "    # Mean impute Age\n",
    "    X['Age'] = imp_age_mean.transform(X[['Age']])\n",
    "    \n",
    "    '''Encode categorical columns'''\n",
    "    for col in ohe_columns:\n",
    "        enc = cat_encoders[col][0]\n",
    "        result = enc.transform(X[[col]])\n",
    "        ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
    "        result_train = pd.DataFrame(result, columns=ohe_columns)\n",
    "        X = pd.concat([X, result_train], axis=1)\n",
    "        \n",
    "    y_pred_proba = clf.predict_proba(X[columns_to_score])\n",
    "    y_pred = (y_pred_proba[:,0] < threshold).astype(np.int16)\n",
    "    d = {\"index\":data[\"PassengerId\"],\n",
    "         \"label\":y_pred,\n",
    "         \"probability_0\":y_pred_proba[:,0],\n",
    "         \"probability_1\":y_pred_proba[:,1]}\n",
    "    \n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9dbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_1_scoring(X_test).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
